{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT = 'processced df.csv'\n",
    "# OUTPUT = 'processced text.csv'\n",
    "# TFIDF_MAT=\"tfidf_matrix.npz\"\n",
    "# BOW_MAT=\"bow_matrix.npz\"\n",
    "# COUNT_VEC='out/count_vectorizer.pkl'\n",
    "# TFIDF_VEC=\"out/tfidf_vectorizer.pkl\"\n",
    "INPUT=\"../api/processed_articles.csv\"\n",
    "OUTPUT=\"../api/processed_text.csv\"\n",
    "TFIDF_MAT=\"../api/tfidf_matrix.npz\"\n",
    "BOW_MAT=\"../api/bow_matrix.npz\"\n",
    "COUNT_VEC=\"../api/out/count_vectorizer.pkl\"\n",
    "TFIDF_VEC=\"../api/out/tfidf_vectorizer.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56631bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a8ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processced df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf072374",
   "metadata": {},
   "source": [
    "### Text Preprocessing Function: Combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05225578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # lowercase text\n",
    "    text = text.lower()\n",
    "    # remove special characters, punctuation, and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # tokenize and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in stopwords.words('english')]\n",
    "    # join the tokens back into a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# apply this function to 'combined_text' \n",
    "df['preprocessed_text'] = df['combined_text'].apply(preprocess_text)\n",
    "\n",
    "df = df.drop('combined_text', axis=1)\n",
    "# Now the 'preprocessed_text' column will have the cleaned and preprocessed text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26005d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[4, \"preprocessed_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84c647",
   "metadata": {},
   "source": [
    "### Vectorization: Using BoW to Transform Preprocessed Text Data for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#create a countvectorizer instance\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "#apply it to preprocessed text\n",
    "bow_matrix = vectorizer.fit_transform(df['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820d226",
   "metadata": {},
   "source": [
    "### Vectorization: Using TF-IDF to Transform Preprocessed Text Data for NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b33ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# instantiate the TF-IDF \n",
    "tfidf_vect = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000)\n",
    "\n",
    "# apply it to preprocessed text\n",
    "tfidf_matrix = tfidf_vect.fit_transform(df['preprocessed_text'])\n",
    "\n",
    "# tfidf_matrix is a sparse matrix representation of documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a4b23",
   "metadata": {},
   "source": [
    "### \"tfidf_matrix\" is what we will use for Topic Modeling and be served as predictors for the topic classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2645e0",
   "metadata": {},
   "source": [
    "### To better understand the \"tfidf_matrix\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86113be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view as dense matrix\n",
    "dense_tfidf = tfidf_matrix[:5].todense()\n",
    "pd.DataFrame(dense_tfidf, columns=tfidf_vect.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f445ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the shape of the matrix\n",
    "print(\"Shape of tfidf_matrix:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some non-0 TF-IDF values of the first document\n",
    "doc = 0  \n",
    "feature_names = tfidf_vect.get_feature_names_out()\n",
    "print(f\"Non-zero TF-IDF values in document {doc}:\")\n",
    "for word, tfidf_value in zip(feature_names, tfidf_matrix[doc].toarray().flatten()):\n",
    "    if tfidf_value > 0:\n",
    "        print(f\"{word}: {tfidf_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca28598",
   "metadata": {},
   "source": [
    "### Other Features\n",
    "\n",
    "How to use other features for the topic modeling task or the topic classification task, depending on the nature of these features and the goals of our analysis. \n",
    "\n",
    "We will get back to \"other features\" when we do our topic modeling task. \n",
    "\n",
    "We intend to use other features as predictors for our topic classification task. But we need to wait until we obtain the topic labels from our topic modeling results. As we will need to evaluate  which \"other features\" have a meaningful relationship with the topic labels. we may only choose one of them, or combination of few of them based on the consideration of the model complexity and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataset with the preprocessed text\n",
    "df.to_csv(OUTPUT, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bde037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "# save tfidf_matrix\n",
    "sparse.save_npz(TFIDF_MAT, tfidf_matrix)\n",
    "sparse.save_npz(BOW_MAT, bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546cd92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "022c9e7e",
   "metadata": {},
   "source": [
    "# Pickling the vectorizer to use in different notebooks\n",
    "\n",
    "To analyze the different topics visually - we can print the words associated to a topic. To do this, we need access to the vectorizer instance across different jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(COUNT_VEC, 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(TFIDF_VEC, 'wb') as f:\n",
    "    pickle.dump(tfidf_vect, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa0d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
