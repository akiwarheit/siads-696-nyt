{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56631bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\qfu88\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\qfu88\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a8ee5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_of_material</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>section_name</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>News</td>\n",
       "      <td>Lifestyle &amp; Leisure</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>Point of view — prescriptive, descriptive and ...</td>\n",
       "      <td>Penelope Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>News</td>\n",
       "      <td>Lifestyle &amp; Leisure</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>Ten high-end design galleries will offer 30 to...</td>\n",
       "      <td>Marianne Rohrlich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Bankers may be suffering but the decline in de...</td>\n",
       "      <td>Lauren Laughlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News</td>\n",
       "      <td>National</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Florida scaled back its purchase of sugar comp...</td>\n",
       "      <td>Damien Cave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>News</td>\n",
       "      <td>Business</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Take-Two Interactive, the maker of Grand Theft...</td>\n",
       "      <td>Bloomberg News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type_of_material            news_desk   section_name  \\\n",
       "0             News  Lifestyle & Leisure  Home & Garden   \n",
       "1             News  Lifestyle & Leisure  Home & Garden   \n",
       "2             News             Business   Business Day   \n",
       "3             News             National           U.S.   \n",
       "4             News             Business     Technology   \n",
       "\n",
       "                                       combined_text             author  \n",
       "0  Point of view — prescriptive, descriptive and ...     Penelope Green  \n",
       "1  Ten high-end design galleries will offer 30 to...  Marianne Rohrlich  \n",
       "2  Bankers may be suffering but the decline in de...    Lauren Laughlin  \n",
       "3  Florida scaled back its purchase of sugar comp...        Damien Cave  \n",
       "4  Take-Two Interactive, the maker of Grand Theft...     Bloomberg News  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('processced df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf072374",
   "metadata": {},
   "source": [
    "### Text Preprocessing Function: Combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05225578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # lowercase text\n",
    "    text = text.lower()\n",
    "    # remove special characters, punctuation, and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # tokenize and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in stopwords.words('english')]\n",
    "    # join the tokens back into a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# apply this function to 'combined_text' \n",
    "df['preprocessed_text'] = df['combined_text'].apply(preprocess_text)\n",
    "\n",
    "df = df.drop('combined_text', axis=1)\n",
    "# Now the 'preprocessed_text' column will have the cleaned and preprocessed text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c6f58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_of_material</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>section_name</th>\n",
       "      <th>author</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>News</td>\n",
       "      <td>Lifestyle &amp; Leisure</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>Penelope Green</td>\n",
       "      <td>point view   prescriptive descriptive definite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>News</td>\n",
       "      <td>Lifestyle &amp; Leisure</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>Marianne Rohrlich</td>\n",
       "      <td>ten highend design gallery offer     percent m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Lauren Laughlin</td>\n",
       "      <td>banker may suffer decline dealmaking also take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News</td>\n",
       "      <td>National</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Damien Cave</td>\n",
       "      <td>florida scale back purchase sugar company land...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>News</td>\n",
       "      <td>Business</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Bloomberg News</td>\n",
       "      <td>taketwo interactive maker grand theft auto acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type_of_material            news_desk   section_name             author  \\\n",
       "0             News  Lifestyle & Leisure  Home & Garden     Penelope Green   \n",
       "1             News  Lifestyle & Leisure  Home & Garden  Marianne Rohrlich   \n",
       "2             News             Business   Business Day    Lauren Laughlin   \n",
       "3             News             National           U.S.        Damien Cave   \n",
       "4             News             Business     Technology     Bloomberg News   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  point view   prescriptive descriptive definite...  \n",
       "1  ten highend design gallery offer     percent m...  \n",
       "2  banker may suffer decline dealmaking also take...  \n",
       "3  florida scale back purchase sugar company land...  \n",
       "4  taketwo interactive maker grand theft auto acc...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26005d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taketwo interactive maker grand theft auto accuse backdate option historically low price scheme reward key employee taketwo interactive software maker grand theft auto video game agree pay   million settle lawsuit security exchange commission accuse company backdate stock option video game maker pay   million settle stock option case suit litigation taketwo interactive software inc stock option purchase plan security commodity violation\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[4, \"preprocessed_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84c647",
   "metadata": {},
   "source": [
    "### Vectorization: Using BoW to Transform Preprocessed Text Data for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a69b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#create a countvectorizer instance\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "#apply it to preprocessed text\n",
    "bow_matrix = vectorizer.fit_transform(df['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820d226",
   "metadata": {},
   "source": [
    "### Vectorization: Using TF-IDF to Transform Preprocessed Text Data for NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b33ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# instantiate the TF-IDF \n",
    "tfidf_vect = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000)\n",
    "\n",
    "# apply it to preprocessed text\n",
    "tfidf_matrix = tfidf_vect.fit_transform(df['preprocessed_text'])\n",
    "\n",
    "# tfidf_matrix is a sparse matrix representation of documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a4b23",
   "metadata": {},
   "source": [
    "### \"tfidf_matrix\" is what we will use for Topic Modeling and be served as predictors for the topic classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2645e0",
   "metadata": {},
   "source": [
    "### To better understand the \"tfidf_matrix\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86113be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abortion</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accident</th>\n",
       "      <th>accord</th>\n",
       "      <th>accuse</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actress</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>writing</th>\n",
       "      <th>yankee</th>\n",
       "      <th>yankees</th>\n",
       "      <th>year</th>\n",
       "      <th>yearold</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abortion  abuse  accident  accord    accuse  across  act  action  actor  \\\n",
       "0       0.0    0.0       0.0     0.0  0.000000     0.0  0.0     0.0    0.0   \n",
       "1       0.0    0.0       0.0     0.0  0.000000     0.0  0.0     0.0    0.0   \n",
       "2       0.0    0.0       0.0     0.0  0.000000     0.0  0.0     0.0    0.0   \n",
       "3       0.0    0.0       0.0     0.0  0.000000     0.0  0.0     0.0    0.0   \n",
       "4       0.0    0.0       0.0     0.0  0.314085     0.0  0.0     0.0    0.0   \n",
       "\n",
       "   actress  ...  write  writer  writing  yankee  yankees  year  yearold  \\\n",
       "0      0.0  ...    0.0     0.0      0.0     0.0      0.0   0.0      0.0   \n",
       "1      0.0  ...    0.0     0.0      0.0     0.0      0.0   0.0      0.0   \n",
       "2      0.0  ...    0.0     0.0      0.0     0.0      0.0   0.0      0.0   \n",
       "3      0.0  ...    0.0     0.0      0.0     0.0      0.0   0.0      0.0   \n",
       "4      0.0  ...    0.0     0.0      0.0     0.0      0.0   0.0      0.0   \n",
       "\n",
       "        yet  york  young  \n",
       "0  0.000000   0.0    0.0  \n",
       "1  0.000000   0.0    0.0  \n",
       "2  0.000000   0.0    0.0  \n",
       "3  0.159553   0.0    0.0  \n",
       "4  0.000000   0.0    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view as dense matrix\n",
    "dense_tfidf = tfidf_matrix[:5].todense()\n",
    "pd.DataFrame(dense_tfidf, columns=tfidf_vect.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20f445ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tfidf_matrix: (7064, 1000)\n"
     ]
    }
   ],
   "source": [
    "# display the shape of the matrix\n",
    "print(\"Shape of tfidf_matrix:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3017edfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero TF-IDF values in document 0:\n",
      "approach: 0.16513633530413127\n",
      "book: 0.5886450470756803\n",
      "design: 0.15932135888761217\n",
      "elizabeth: 0.3249025991244571\n",
      "fill: 0.16245129956222856\n",
      "film: 0.14515339432689328\n",
      "first: 0.20053530838247816\n",
      "like: 0.21363509583790666\n",
      "literature: 0.12646568649139922\n",
      "page: 0.32564066974573225\n",
      "point: 0.27680361188442515\n",
      "room: 0.15589582412759506\n",
      "title: 0.15648998314298898\n",
      "view: 0.3083629708335429\n",
      "watch: 0.13939766322972955\n"
     ]
    }
   ],
   "source": [
    "# print some non-0 TF-IDF values of the first document\n",
    "doc = 0  \n",
    "feature_names = tfidf_vect.get_feature_names_out()\n",
    "print(f\"Non-zero TF-IDF values in document {doc}:\")\n",
    "for word, tfidf_value in zip(feature_names, tfidf_matrix[doc].toarray().flatten()):\n",
    "    if tfidf_value > 0:\n",
    "        print(f\"{word}: {tfidf_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca28598",
   "metadata": {},
   "source": [
    "### Other Features\n",
    "\n",
    "How to use other features for the topic modeling task or the topic classification task, depending on the nature of these features and the goals of our analysis. \n",
    "\n",
    "We will get back to \"other features\" when we do our topic modeling task. \n",
    "\n",
    "We intend to use other features as predictors for our topic classification task. But we need to wait until we obtain the topic labels from our topic modeling results. As we will need to evaluate  which \"other features\" have a meaningful relationship with the topic labels. we may only choose one of them, or combination of few of them based on the consideration of the model complexity and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed31bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataset with the preprocessed text\n",
    "df.to_csv('processced text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01bde037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "# save tfidf_matrix\n",
    "sparse.save_npz(\"tfidf_matrix.npz\", tfidf_matrix)\n",
    "sparse.save_npz(\"bow_matrix.npz\", bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546cd92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "022c9e7e",
   "metadata": {},
   "source": [
    "# Pickling the vectorizer to use in different notebooks\n",
    "\n",
    "To analyze the different topics visually - we can print the words associated to a topic. To do this, we need access to the vectorizer instance across different jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a20f163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('out/count_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "312c6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('out/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vect, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa0d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
